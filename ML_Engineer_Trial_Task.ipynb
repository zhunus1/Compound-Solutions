{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhunus1/Compound-Solutions/blob/main/ML_Engineer_Trial_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qiEXTP1xF56u"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries\n",
        "import io\n",
        "import nltk\n",
        "import spacy\n",
        "import heapq\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uoi2EqgmCqCT",
        "outputId": "c14d4e23-be83-44cf-e512-dfd643a9ab47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vOOjYmBl2WI0"
      },
      "outputs": [],
      "source": [
        "#Let's see the content of the csv and txt files\n",
        "terms = pd.read_csv('drive/MyDrive/colab/Standardised terms.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHNFTe662dlr",
        "outputId": "54fb0459-335d-4e4d-9eb1-98a09ed6db4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               Utilise resources\n",
              "1            Enhance productivity\n",
              "2             Conduct an analysis\n",
              "3        Maintain a high standard\n",
              "4        Implement best practices\n",
              "5               Ensure compliance\n",
              "6           Streamline operations\n",
              "7               Foster innovation\n",
              "8                    Drive growth\n",
              "9              Leverage synergies\n",
              "10         Demonstrate leadership\n",
              "11         Exercise due diligence\n",
              "12     Maximize stakeholder value\n",
              "13               Prioritise tasks\n",
              "14       Facilitate collaboration\n",
              "15    Monitor performance metrics\n",
              "16             Execute strategies\n",
              "17            Gauge effectiveness\n",
              "18                Champion change\n",
              "Name: Optimal performance, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "terms['Optimal performance']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "excHw8YD2quP",
        "outputId": "9c70148e-e5f7-4586-94e6-a6dc456ab2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = open(\"drive/MyDrive/colab/sample_text.txt\", \"r\")\n",
        "text = file_path.read()\n",
        "print(file_path.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lNHtn6ar7mg3"
      },
      "outputs": [],
      "source": [
        "vector_path = 'drive/MyDrive/colab/wiki-news-300d-1M.vec'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4MxagCoCbsa-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKWYDWRGFk1l"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gEYzEk9s269K"
      },
      "outputs": [],
      "source": [
        "#Now let's initialize FastText model with pre-trained vectors\n",
        "\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(vector_path, binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u5RcyMzc4bKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f5b0fd-398c-418e-e955-ae19ee8c03c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.620e-02  2.410e-02 -1.150e-02  8.730e-02  5.390e-02 -1.039e-01\n",
            "  2.070e-02 -1.226e-01  1.690e-01  3.300e-03  1.400e-02  4.120e-02\n",
            " -3.700e-03  1.782e-01 -3.010e-02  3.480e-02 -3.330e-02  7.560e-02\n",
            " -7.240e-02 -2.760e-02  2.900e-02  1.830e-02 -5.400e-03  1.462e-01\n",
            "  5.610e-02 -1.090e-01 -5.080e-02 -5.070e-02 -3.740e-02  5.300e-03\n",
            "  2.620e-02  6.800e-03  2.200e-03  5.700e-02  3.700e-03  3.970e-02\n",
            "  6.400e-03 -9.400e-03  4.510e-02 -5.710e-02  1.470e-02 -8.800e-03\n",
            " -1.282e-01  2.130e-02 -1.036e-01  2.660e-02  2.440e-02  8.810e-02\n",
            " -9.200e-03  6.910e-02 -8.060e-02 -7.940e-02 -5.727e-01 -6.900e-03\n",
            "  7.150e-02  1.282e-01  2.860e-02 -1.841e-01 -3.370e-02  1.910e-02\n",
            "  4.470e-02 -5.000e-03  1.245e-01 -6.700e-03  1.420e-02 -2.276e-01\n",
            "  7.370e-02 -5.790e-02  1.290e-02  2.450e-02 -3.320e-02 -3.900e-02\n",
            "  6.950e-02 -1.728e-01  1.670e-02 -5.500e-03 -2.090e-02 -3.750e-02\n",
            " -6.460e-02 -5.380e-02  3.350e-02 -3.990e-02 -2.490e-02 -2.119e-01\n",
            " -3.400e-02  6.140e-02 -3.090e-02 -4.620e-02 -3.090e-02  6.510e-02\n",
            "  1.360e-01 -2.000e-03 -9.960e-02  7.330e-02  6.100e-03  5.570e-02\n",
            " -4.340e-02 -9.900e-02  7.300e-03 -4.600e-03 -1.218e-01 -3.760e-02\n",
            "  1.000e-04  6.610e-02  4.860e-02 -1.158e-01  9.330e-02  1.538e-01\n",
            " -1.478e-01  7.870e-02  3.870e-02 -1.186e-01  7.370e-02 -3.580e-02\n",
            "  6.900e-03  2.150e-02 -5.600e-03 -1.551e-01  2.640e-02 -4.455e-01\n",
            " -1.134e-01 -2.500e-02 -1.456e-01 -5.710e-02  6.180e-02  1.677e-01\n",
            "  9.000e-04 -3.422e-01  9.450e-02  3.900e-02  1.191e-01 -3.410e-02\n",
            " -1.224e-01  3.740e-02  1.120e-02  2.820e-02  8.280e-02  3.450e-02\n",
            " -4.470e-02  2.920e-02 -8.040e-02  5.840e-02 -9.530e-02  2.161e-01\n",
            "  6.520e-02 -4.140e-02  6.300e-03 -4.720e-02  8.100e-03 -1.342e-01\n",
            "  1.350e-01  7.820e-02  6.990e-02 -1.760e-02  7.390e-02 -3.310e-02\n",
            " -8.580e-02  7.300e-03  5.280e-02 -6.640e-02 -1.438e-01  3.450e-02\n",
            " -2.960e-02  1.710e-02 -2.452e-01  4.900e-03  1.097e-01  1.089e-01\n",
            "  6.390e-02 -9.300e-03 -2.327e-01  1.011e-01  7.060e-02 -4.230e-02\n",
            "  5.010e-02 -1.030e-01  2.394e-01  1.070e-01 -9.070e-02  8.230e-02\n",
            "  6.780e-02  8.130e-02  9.340e-02 -1.800e-03 -2.000e-04 -9.410e-02\n",
            " -3.680e-02 -9.970e-02  2.109e-01  1.740e-02  1.602e-01 -5.730e-02\n",
            "  4.600e-02  3.070e-02 -7.660e-02 -2.300e-03  4.970e-02 -1.880e-02\n",
            "  9.740e-02  3.000e-03 -3.100e-02 -1.425e-01 -3.170e-02 -3.480e-02\n",
            " -4.110e-02  2.870e-02 -6.700e-02 -2.818e-01 -9.300e-03 -1.500e-02\n",
            "  6.870e-02 -2.430e-02  5.960e-02  2.350e-02 -2.090e-02  4.130e-02\n",
            " -2.440e-02  2.250e-02 -1.322e-01  1.672e-01 -3.080e-02  3.340e-02\n",
            "  8.650e-02 -5.550e-02  1.159e-01  1.752e-01 -9.590e-02  9.730e-02\n",
            "  7.740e-02 -2.396e-01 -2.483e-01  2.470e-02  3.802e-01 -1.259e-01\n",
            " -6.840e-02  2.190e-01  8.690e-02  3.440e-02 -2.691e-01 -4.300e-03\n",
            " -9.700e-03 -7.700e-02 -1.500e-02  6.600e-02  1.440e-02 -1.820e-02\n",
            " -7.940e-02  4.100e-02 -8.910e-02  1.671e-01  4.320e-02 -9.740e-02\n",
            " -8.490e-02  2.980e-02  1.590e-02  9.630e-02 -2.410e-02  5.900e-03\n",
            " -2.410e-02 -2.210e-02  1.627e-01  1.660e-02  5.990e-02 -9.200e-03\n",
            " -1.643e-01 -5.500e-03  9.410e-02 -2.040e-02 -1.981e-01  1.070e-01\n",
            "  3.730e-02  1.330e-02 -5.240e-02  5.840e-02  2.370e-02 -2.220e-02\n",
            "  8.870e-02  8.000e-04  2.120e-02 -2.800e-02 -2.650e-02  1.446e-01\n",
            " -6.840e-02 -3.320e-02  4.350e-02  9.020e-02 -5.040e-02 -5.440e-02\n",
            " -2.150e-02  6.360e-02 -7.530e-02 -3.920e-02 -2.820e-02 -7.420e-02\n",
            " -1.402e-01  1.583e-01 -9.630e-02  1.671e-01  9.680e-02  9.500e-02]\n"
          ]
        }
      ],
      "source": [
        "word_vector = word2vec_model['example']\n",
        "print(word_vector)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = word2vec_model.most_similar('example', topn=5)\n",
        "print(similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8DoHzVgTc0i",
        "outputId": "1a721de8-c44c-4f50-bba8-9000dee92bc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('instance', 0.8516244888305664), ('example.', 0.7244152426719666), ('exmaple', 0.7096107602119446), ('example-', 0.690764307975769), ('examples', 0.6854547262191772)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load spaCy model (for tokenization and more)\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5RiO85kTg5s",
        "outputId": "329aa440-1b9b-4136-e292-93e0e1a81fc1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cosine_similarity(feature_vec_1, feature_vec_2):\n",
        "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
      ],
      "metadata": {
        "id": "n-PUnoGoWMpy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Tokenization and Lowercasing\n",
        "def tokenize_and_lowercase(text):\n",
        "    # Use spaCy for tokenization\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text.lower() for token in doc if not token.is_punct and not token.is_space]\n",
        "    return tokens\n",
        "\n",
        "tokens = tokenize_and_lowercase(text)\n",
        "print(\"Tokenized and Lowercased Text:\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCsPJlfXU4HI",
        "outputId": "af838ec4-f343-4950-9ff9-78044811cf06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized and Lowercased Text:\n",
            "['in', 'today', \"'s\", 'meeting', 'we', 'discussed', 'a', 'variety', 'of', 'issues', 'affecting', 'our', 'department', 'the', 'weather', 'was', 'unusually', 'sunny', 'a', 'pleasant', 'backdrop', 'to', 'our', 'serious', 'discussions', 'we', 'came', 'to', 'the', 'consensus', 'that', 'we', 'need', 'to', 'do', 'better', 'in', 'terms', 'of', 'performance', 'sally', 'brought', 'doughnuts', 'which', 'lightened', 'the', 'mood', 'it', \"'s\", 'important', 'to', 'make', 'good', 'use', 'of', 'what', 'we', 'have', 'at', 'our', 'disposal', 'during', 'the', 'coffee', 'break', 'we', 'talked', 'about', 'the', 'upcoming', 'company', 'picnic', 'we', 'should', 'aim', 'to', 'be', 'more', 'efficient', 'and', 'look', 'for', 'ways', 'to', 'be', 'more', 'creative', 'in', 'our', 'daily', 'tasks', 'growth', 'is', 'essential', 'for', 'our', 'future', 'but', 'equally', 'important', 'is', 'building', 'strong', 'relationships', 'with', 'our', 'team', 'members', 'as', 'a', 'reminder', 'the', 'annual', 'staff', 'survey', 'is', 'due', 'next', 'friday', 'lastly', 'we', 'agreed', 'that', 'we', 'must', 'take', 'time', 'to', 'look', 'over', 'our', 'plans', 'carefully', 'and', 'consider', 'all', 'angles', 'before', 'moving', 'forward', 'on', 'a', 'side', 'note', 'david', 'mentioned', 'that', 'his', 'cat', 'is', 'recovering', 'well', 'from', 'surgery']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Removing stop words\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "filtered_tokens = remove_stopwords(tokens)\n",
        "print(\"\\nText after Stopword Removal:\")\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IzHmKNJVffq",
        "outputId": "a3c9f2b2-271b-4959-f75a-def686a87aa7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text after Stopword Removal:\n",
            "['today', \"'s\", 'meeting', 'discussed', 'variety', 'issues', 'affecting', 'department', 'weather', 'unusually', 'sunny', 'pleasant', 'backdrop', 'serious', 'discussions', 'came', 'consensus', 'need', 'better', 'terms', 'performance', 'sally', 'brought', 'doughnuts', 'lightened', 'mood', \"'s\", 'important', 'make', 'good', 'use', 'disposal', 'coffee', 'break', 'talked', 'upcoming', 'company', 'picnic', 'aim', 'efficient', 'look', 'ways', 'creative', 'daily', 'tasks', 'growth', 'essential', 'future', 'equally', 'important', 'building', 'strong', 'relationships', 'team', 'members', 'reminder', 'annual', 'staff', 'survey', 'due', 'next', 'friday', 'lastly', 'agreed', 'must', 'take', 'time', 'look', 'plans', 'carefully', 'consider', 'angles', 'moving', 'forward', 'side', 'note', 'david', 'mentioned', 'cat', 'recovering', 'well', 'surgery']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Removing Special Characters and Digits\n",
        "def remove_special_characters(tokens):\n",
        "    filtered_tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens]\n",
        "    filtered_tokens = [token for token in filtered_tokens if token]  # Remove empty strings\n",
        "    return filtered_tokens\n",
        "\n",
        "cleaned_tokens = remove_special_characters(filtered_tokens)\n",
        "print(\"\\nText after Removing Special Characters and Digits:\")\n",
        "print(cleaned_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjLJBx0rWHom",
        "outputId": "bf8b44e9-0d95-41ed-e196-29ad5c9b2a7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text after Removing Special Characters and Digits:\n",
            "['today', 's', 'meeting', 'discussed', 'variety', 'issues', 'affecting', 'department', 'weather', 'unusually', 'sunny', 'pleasant', 'backdrop', 'serious', 'discussions', 'came', 'consensus', 'need', 'better', 'terms', 'performance', 'sally', 'brought', 'doughnuts', 'lightened', 'mood', 's', 'important', 'make', 'good', 'use', 'disposal', 'coffee', 'break', 'talked', 'upcoming', 'company', 'picnic', 'aim', 'efficient', 'look', 'ways', 'creative', 'daily', 'tasks', 'growth', 'essential', 'future', 'equally', 'important', 'building', 'strong', 'relationships', 'team', 'members', 'reminder', 'annual', 'staff', 'survey', 'due', 'next', 'friday', 'lastly', 'agreed', 'must', 'take', 'time', 'look', 'plans', 'carefully', 'consider', 'angles', 'moving', 'forward', 'side', 'note', 'david', 'mentioned', 'cat', 'recovering', 'well', 'surgery']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Apply the same preprocessing for terms\n",
        "cleaned_terms = []\n",
        "for term in terms['Optimal performance']:\n",
        "  tokens = tokenize_and_lowercase(term)\n",
        "  filtered_tokens = remove_stopwords(tokens)\n",
        "  clenaed_term = remove_stopwords(filtered_tokens)\n",
        "  cleaned_terms.append(clenaed_term)"
      ],
      "metadata": {
        "id": "pT8-FoOcX-r2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_terms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BGxMcQpcDAp",
        "outputId": "029d0f86-4d90-48e6-a6e7-dc18a9eb7c09"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['utilise', 'resources'],\n",
              " ['enhance', 'productivity'],\n",
              " ['conduct', 'analysis'],\n",
              " ['maintain', 'high', 'standard'],\n",
              " ['implement', 'best', 'practices'],\n",
              " ['ensure', 'compliance'],\n",
              " ['streamline', 'operations'],\n",
              " ['foster', 'innovation'],\n",
              " ['drive', 'growth'],\n",
              " ['leverage', 'synergies'],\n",
              " ['demonstrate', 'leadership'],\n",
              " ['exercise', 'due', 'diligence'],\n",
              " ['maximize', 'stakeholder', 'value'],\n",
              " ['prioritise', 'tasks'],\n",
              " ['facilitate', 'collaboration'],\n",
              " ['monitor', 'performance', 'metrics'],\n",
              " ['execute', 'strategies'],\n",
              " ['gauge', 'effectiveness'],\n",
              " ['champion', 'change']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Let's calculate vector for each term\n",
        "\n",
        "terms_vectors = {}\n",
        "\n",
        "for i in range(len(cleaned_terms)):\n",
        "  word_vector = np.zeros((1, word2vec_model.vector_size), dtype=np.float32)\n",
        "  for word in cleaned_terms[i]:\n",
        "    if word in word2vec_model:\n",
        "      if word_vector is None:\n",
        "        word_vector = word2vec_model[word]\n",
        "      else:\n",
        "        word_vector += word2vec_model[word]\n",
        "  if np.linalg.norm(word_vector) > 0:\n",
        "    word_vector /= np.linalg.norm(word_vector)\n",
        "  terms_vectors[terms['Optimal performance'][i]] = word_vector\n",
        "\n"
      ],
      "metadata": {
        "id": "3L20xinccDRH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Let's calculate vector for each word of the text\n",
        "\n",
        "term_suggestions = {}\n",
        "\n",
        "word_vector = np.zeros((1, word2vec_model.vector_size), dtype=np.float32)\n",
        "for word in cleaned_tokens:\n",
        "  if word in word2vec_model:\n",
        "    if word_vector is None:\n",
        "      word_vector = word2vec_model[word]\n",
        "    else:\n",
        "      word_vector += word2vec_model[word]\n",
        "  if np.linalg.norm(word_vector) > 0:\n",
        "    word_vector /= np.linalg.norm(word_vector)\n",
        "\n",
        "  # Calculate cosine similarities between the word and all terms\n",
        "  similarities = {term: cosine_similarity(word_vector, term_vector)[0][0] for term, term_vector in terms_vectors.items()}\n",
        "\n",
        "   # Find the term with the highest similarity\n",
        "  most_similar_term = max(similarities, key=similarities.get)\n",
        "\n",
        "  # Store the term and its suggested word in the dictionary\n",
        "  term_suggestions[most_similar_term] = word\n",
        "\n",
        "# Print the term and suggested word for each word in the input text\n",
        "for term, suggested_word in term_suggestions.items():\n",
        "    print(f\"Term: '{term}', Suggested Word for Replacement: '{suggested_word}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpKpt0wlcfQj",
        "outputId": "7657af07-800b-4d68-a22c-d42ba80e98cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Term: 'Maintain a high standard', Suggested Word for Replacement: 'well'\n",
            "Term: 'Implement best practices', Suggested Word for Replacement: 'surgery'\n",
            "Term: 'Demonstrate leadership', Suggested Word for Replacement: 'take'\n",
            "Term: 'Monitor performance metrics', Suggested Word for Replacement: 'team'\n",
            "Term: 'Conduct an analysis', Suggested Word for Replacement: 'survey'\n",
            "Term: 'Streamline operations', Suggested Word for Replacement: 'moving'\n",
            "Term: 'Execute strategies', Suggested Word for Replacement: 'angles'\n",
            "Term: 'Drive growth', Suggested Word for Replacement: 'growth'\n",
            "Term: 'Enhance productivity', Suggested Word for Replacement: 'mood'\n",
            "Term: 'Utilise resources', Suggested Word for Replacement: 'disposal'\n",
            "Term: 'Champion change', Suggested Word for Replacement: 'cat'\n",
            "Term: 'Prioritise tasks', Suggested Word for Replacement: 'tasks'\n",
            "Term: 'Exercise due diligence', Suggested Word for Replacement: 'lastly'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bigrams(text):\n",
        "    words = text.split()\n",
        "    bigrams = [f\"{words[i]} {words[i+1]}\" for i in range(len(words) - 1)]\n",
        "    return bigrams"
      ],
      "metadata": {
        "id": "7MIlnFSUjO6k"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract bigrams from the input text\n",
        "text_bigrams = [f\"{cleaned_tokens[i]} {cleaned_tokens[i+1]}\" for i in range(len(cleaned_tokens) - 1)]\n",
        "\n",
        "# Calculate the vector representation for the terms\n",
        "term_vectors = {}\n",
        "for i in range(len(cleaned_terms)):\n",
        "    term_vector = np.zeros((1, word2vec_model.vector_size), dtype=np.float32)\n",
        "    for word in cleaned_terms[i]:\n",
        "      if word in word2vec_model:\n",
        "        if term_vector is None:\n",
        "          term_vector = word2vec_model[word]\n",
        "        else:\n",
        "          term_vector += word2vec_model[word]\n",
        "      # Normalize the term vector\n",
        "      if np.linalg.norm(term_vector) > 0:\n",
        "        term_vector /= np.linalg.norm(term_vector)\n",
        "    term_vectors[terms['Optimal performance'][i]] = term_vector"
      ],
      "metadata": {
        "id": "M9EfEG8_mV34"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store bigram-to-suggested-term mappings\n",
        "bigram_suggestions = {}\n",
        "\n",
        "# Find the most similar term for each bigram in the text\n",
        "for bigram in text_bigrams:\n",
        "    words = re.split(r'\\s+', bigram)\n",
        "    word_vectors = [word2vec_model[word] for word in words if word in word2vec_model]\n",
        "    if word_vectors:\n",
        "        bigram_vector = sum(word_vectors)\n",
        "        bigram_vector = bigram_vector.reshape(1, -1)\n",
        "        bigram_vector /= np.linalg.norm(bigram_vector)\n",
        "\n",
        "        # Calculate cosine similarities between the bigram and all terms\n",
        "        similarities = {term: cosine_similarity(bigram_vector, term_vector)[0][0] for term, term_vector in term_vectors.items()}\n",
        "\n",
        "        # Find the term with the highest similarity and its associated score\n",
        "        most_similar_term, highest_similarity_score = max(similarities.items(), key=lambda x: x[1])\n",
        "\n",
        "        # Store the bigram, its suggested term, and the similarity score in the dictionary\n",
        "        bigram_suggestions[bigram] = (most_similar_term, highest_similarity_score)\n",
        "\n"
      ],
      "metadata": {
        "id": "TOMbj8zKotKl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for bigram, (suggested_term, similarity_score) in bigram_suggestions.items():\n",
        "    print(f\"Text phrase: '{bigram}', Suggested Term for Replacement: '{suggested_term}', Similarity Score: {int(similarity_score*100)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofU24qceS28s",
        "outputId": "120a020f-fb43-42fa-bfa4-5bf926c10251"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text phrase: 'today s', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 54%\n",
            "Text phrase: 's meeting', Suggested Term for Replacement: 'Demonstrate leadership', Similarity Score: 54%\n",
            "Text phrase: 'meeting discussed', Suggested Term for Replacement: 'Facilitate collaboration', Similarity Score: 50%\n",
            "Text phrase: 'discussed variety', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 58%\n",
            "Text phrase: 'variety issues', Suggested Term for Replacement: 'Prioritise tasks', Similarity Score: 60%\n",
            "Text phrase: 'issues affecting', Suggested Term for Replacement: 'Conduct an analysis', Similarity Score: 56%\n",
            "Text phrase: 'affecting department', Suggested Term for Replacement: 'Streamline operations', Similarity Score: 58%\n",
            "Text phrase: 'department weather', Suggested Term for Replacement: 'Streamline operations', Similarity Score: 57%\n",
            "Text phrase: 'weather unusually', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 51%\n",
            "Text phrase: 'unusually sunny', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 50%\n",
            "Text phrase: 'sunny pleasant', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 45%\n",
            "Text phrase: 'pleasant backdrop', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 50%\n",
            "Text phrase: 'backdrop serious', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 57%\n",
            "Text phrase: 'serious discussions', Suggested Term for Replacement: 'Conduct an analysis', Similarity Score: 61%\n",
            "Text phrase: 'discussions came', Suggested Term for Replacement: 'Conduct an analysis', Similarity Score: 56%\n",
            "Text phrase: 'came consensus', Suggested Term for Replacement: 'Champion change', Similarity Score: 52%\n",
            "Text phrase: 'consensus need', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 55%\n",
            "Text phrase: 'need better', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 56%\n",
            "Text phrase: 'better terms', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 62%\n",
            "Text phrase: 'terms performance', Suggested Term for Replacement: 'Monitor performance metrics', Similarity Score: 70%\n",
            "Text phrase: 'performance sally', Suggested Term for Replacement: 'Monitor performance metrics', Similarity Score: 53%\n",
            "Text phrase: 'sally brought', Suggested Term for Replacement: 'Champion change', Similarity Score: 45%\n",
            "Text phrase: 'brought doughnuts', Suggested Term for Replacement: 'Foster innovation', Similarity Score: 45%\n",
            "Text phrase: 'doughnuts lightened', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 42%\n",
            "Text phrase: 'lightened mood', Suggested Term for Replacement: 'Enhance productivity', Similarity Score: 46%\n",
            "Text phrase: 'mood s', Suggested Term for Replacement: 'Conduct an analysis', Similarity Score: 52%\n",
            "Text phrase: 's important', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 53%\n",
            "Text phrase: 'important make', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 57%\n",
            "Text phrase: 'make good', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 60%\n",
            "Text phrase: 'good use', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 66%\n",
            "Text phrase: 'use disposal', Suggested Term for Replacement: 'Utilise resources', Similarity Score: 63%\n",
            "Text phrase: 'disposal coffee', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 52%\n",
            "Text phrase: 'coffee break', Suggested Term for Replacement: 'Champion change', Similarity Score: 53%\n",
            "Text phrase: 'break talked', Suggested Term for Replacement: 'Champion change', Similarity Score: 56%\n",
            "Text phrase: 'talked upcoming', Suggested Term for Replacement: 'Champion change', Similarity Score: 49%\n",
            "Text phrase: 'upcoming company', Suggested Term for Replacement: 'Streamline operations', Similarity Score: 56%\n",
            "Text phrase: 'company picnic', Suggested Term for Replacement: 'Streamline operations', Similarity Score: 50%\n",
            "Text phrase: 'picnic aim', Suggested Term for Replacement: 'Prioritise tasks', Similarity Score: 51%\n",
            "Text phrase: 'aim efficient', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 58%\n",
            "Text phrase: 'efficient look', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 57%\n",
            "Text phrase: 'look ways', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 64%\n",
            "Text phrase: 'ways creative', Suggested Term for Replacement: 'Execute strategies', Similarity Score: 66%\n",
            "Text phrase: 'creative daily', Suggested Term for Replacement: 'Drive growth', Similarity Score: 55%\n",
            "Text phrase: 'daily tasks', Suggested Term for Replacement: 'Prioritise tasks', Similarity Score: 85%\n",
            "Text phrase: 'tasks growth', Suggested Term for Replacement: 'Prioritise tasks', Similarity Score: 83%\n",
            "Text phrase: 'growth essential', Suggested Term for Replacement: 'Drive growth', Similarity Score: 81%\n",
            "Text phrase: 'essential future', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 58%\n",
            "Text phrase: 'future equally', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 54%\n",
            "Text phrase: 'equally important', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 54%\n",
            "Text phrase: 'important building', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 56%\n",
            "Text phrase: 'building strong', Suggested Term for Replacement: 'Demonstrate leadership', Similarity Score: 61%\n",
            "Text phrase: 'strong relationships', Suggested Term for Replacement: 'Demonstrate leadership', Similarity Score: 60%\n",
            "Text phrase: 'relationships team', Suggested Term for Replacement: 'Execute strategies', Similarity Score: 62%\n",
            "Text phrase: 'team members', Suggested Term for Replacement: 'Demonstrate leadership', Similarity Score: 58%\n",
            "Text phrase: 'members reminder', Suggested Term for Replacement: 'Demonstrate leadership', Similarity Score: 55%\n",
            "Text phrase: 'reminder annual', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 53%\n",
            "Text phrase: 'annual staff', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 55%\n",
            "Text phrase: 'staff survey', Suggested Term for Replacement: 'Conduct an analysis', Similarity Score: 63%\n",
            "Text phrase: 'survey due', Suggested Term for Replacement: 'Exercise due diligence', Similarity Score: 64%\n",
            "Text phrase: 'due next', Suggested Term for Replacement: 'Exercise due diligence', Similarity Score: 62%\n",
            "Text phrase: 'next friday', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 43%\n",
            "Text phrase: 'friday lastly', Suggested Term for Replacement: 'Execute strategies', Similarity Score: 39%\n",
            "Text phrase: 'lastly agreed', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 50%\n",
            "Text phrase: 'agreed must', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 48%\n",
            "Text phrase: 'must take', Suggested Term for Replacement: 'Champion change', Similarity Score: 50%\n",
            "Text phrase: 'take time', Suggested Term for Replacement: 'Champion change', Similarity Score: 57%\n",
            "Text phrase: 'time look', Suggested Term for Replacement: 'Champion change', Similarity Score: 55%\n",
            "Text phrase: 'look plans', Suggested Term for Replacement: 'Execute strategies', Similarity Score: 65%\n",
            "Text phrase: 'plans carefully', Suggested Term for Replacement: 'Execute strategies', Similarity Score: 63%\n",
            "Text phrase: 'carefully consider', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 52%\n",
            "Text phrase: 'consider angles', Suggested Term for Replacement: 'Execute strategies', Similarity Score: 56%\n",
            "Text phrase: 'angles moving', Suggested Term for Replacement: 'Streamline operations', Similarity Score: 54%\n",
            "Text phrase: 'moving forward', Suggested Term for Replacement: 'Champion change', Similarity Score: 56%\n",
            "Text phrase: 'forward side', Suggested Term for Replacement: 'Champion change', Similarity Score: 54%\n",
            "Text phrase: 'side note', Suggested Term for Replacement: 'Champion change', Similarity Score: 53%\n",
            "Text phrase: 'note david', Suggested Term for Replacement: 'Champion change', Similarity Score: 45%\n",
            "Text phrase: 'david mentioned', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 42%\n",
            "Text phrase: 'mentioned cat', Suggested Term for Replacement: 'Champion change', Similarity Score: 49%\n",
            "Text phrase: 'cat recovering', Suggested Term for Replacement: 'Champion change', Similarity Score: 45%\n",
            "Text phrase: 'recovering well', Suggested Term for Replacement: 'Maintain a high standard', Similarity Score: 52%\n",
            "Text phrase: 'well surgery', Suggested Term for Replacement: 'Implement best practices', Similarity Score: 57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEZWoN5lWeUr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}